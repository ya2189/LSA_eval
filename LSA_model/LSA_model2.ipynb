{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_0xDLy0_bLM8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import glob \n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "def load_data(genre):\n",
        "  documents_list = []\n",
        "\n",
        "  path = Path(\"../Dataset/\"+genre+\"_docs/\")\n",
        "  read_files = glob.glob(os.path.join(path,\"*.txt\"))\n",
        "\n",
        "  for f in read_files:\n",
        "    with open(f, \"r\", encoding=\"utf-8\") as doc:\n",
        "      text = doc.read().strip()\n",
        "      documents_list.append(text)\n",
        "  return documents_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def save_embeddings(term2topic, doc2topic, genre, k):\n",
        "    print(\"Saving embeddings ... \")\n",
        "    # save mappings\n",
        "    with open(\"doc2topic_\"+genre+\"_\"+str(k)+\".json\", mode=\"w\", encoding=\"utf-8\") as fp:\n",
        "        json.dump(doc2topic, fp, ensure_ascii=False, indent=4)\n",
        "\n",
        "    with open(\"term2topic_\"+genre+\"_\"+str(k)+\".json\", mode=\"w\", encoding=\"utf-8\") as fp:\n",
        "        json.dump(term2topic, fp, ensure_ascii=False, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def LSA(text_genre, k):\n",
        "    print(\"Training LSA model for genre \"+text_genre+\" and k=\"+str(k))\n",
        "    documents_list = load_data(text_genre)\n",
        "\n",
        "    # Initialize regex tokenizer\n",
        "    tokenizer = RegexpTokenizer(r'\\w+') #\\w+ matches any word character \n",
        "\n",
        "    # Vectorize document using TF-IDF\n",
        "    tfidf = TfidfVectorizer(lowercase=True,\n",
        "                            stop_words='english',\n",
        "                            ngram_range = (1,1),\n",
        "                            tokenizer = tokenizer.tokenize)\n",
        "\n",
        "    # Fit and Transform the documents\n",
        "    train_data = tfidf.fit_transform(documents_list)  \n",
        "\n",
        "    # Define the number of topics or components\n",
        "    num_components=k\n",
        "\n",
        "    # Create SVD object\n",
        "    lsa = TruncatedSVD(n_components=num_components, n_iter=100, random_state=42)\n",
        "\n",
        "    # Fit SVD model on data\n",
        "    U_SIGMA = lsa.fit_transform(train_data) #returns U * SIGMA\n",
        "\n",
        "    # Get Singular values and Components \n",
        "    Sigma = lsa.singular_values_ \n",
        "    V_transpose = lsa.components_.T\n",
        "\n",
        "    U = U_SIGMA / Sigma\n",
        "\n",
        "    # doc2topic from matrix U\n",
        "    doc2topic = {doc: U[idx].tolist() for idx, doc in enumerate(documents_list)}\n",
        "\n",
        "    # term2topic from matrix V\n",
        "    term2topic = {\n",
        "        term: V_transpose[idx].tolist() for term, idx in tfidf.vocabulary_.items()\n",
        "    }\n",
        "\n",
        "    save_embeddings(term2topic, doc2topic, text_genre, num_components)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in range(1, 7): \n",
        "    k = 2**k #k ranges from 2 to 64\n",
        "    LSA(\"poetry\", k)\n",
        "    LSA(\"fiction\", k)\n",
        "    LSA(\"nonfiction\", k)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "LSA_eval_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "eb4dbace500bde27436d6c62a5916e6de58a43b9494da1bf763028544149a815"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
